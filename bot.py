import os
import logging
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes, MessageHandler, filters
import psycopg2
from psycopg2 import sql
from datetime import datetime, timedelta
import jdatetime  # Ø¨Ø±Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
import pytz  # Ø¨Ø±Ø§ÛŒ Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ
import requests
import json

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª
TOKEN = "7584437136:AAFVtfF9RjCyteONcz8DSg2F2CfhgQT2GcQ"

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Hugging Face API
HF_API_TOKEN = os.environ.get('HF_API_TOKEN', '')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³
DB_CONFIG = {
    'dbname': 'exam_bot',
    'user': 'bot_user',
    'password': 'bot_password',
    'host': 'localhost',
    'port': '5432'
}

# Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ ØªÙ‡Ø±Ø§Ù†
TEHRAN_TZ = pytz.timezone('Asia/Tehran')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ¬ÛŒÙ†ÛŒØ´Ù†
QUESTIONS_PER_PAGE = 10  # Ø­Ø¯Ø§Ú©Ø«Ø± Û±Û° Ø³ÙˆØ§Ù„ Ø¯Ø± Ù‡Ø± ØµÙØ­Ù‡

def get_db_connection():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        logger.error(f"Database connection error: {e}")
        return None

# Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
def init_db():
    try:
        conn = get_db_connection()
        if conn is None:
            logger.error("Failed to connect to database for initialization")
            return False
            
        cur = conn.cursor()
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
        cur.execute('''
            CREATE TABLE IF NOT EXISTS exams (
                id SERIAL PRIMARY KEY,
                user_id BIGINT,
                course_name TEXT,
                topic_name TEXT,
                start_question INTEGER,
                end_question INTEGER,
                total_questions INTEGER,
                exam_duration INTEGER DEFAULT 0,
                elapsed_time REAL DEFAULT 0,
                answers TEXT,
                correct_answers TEXT,
                score REAL DEFAULT 0,
                wrong_questions TEXT,
                unanswered_questions TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                jalali_date TEXT,
                tehran_time TEXT,
                question_pattern TEXT DEFAULT 'all'
            )
        ''')
        
        conn.commit()
        cur.close()
        conn.close()
        logger.info("Database initialized successfully")
        return True
    except Exception as e:
        logger.error(f"Error initializing database: {e}")
        return False

# Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ØªÙ‡Ø±Ø§Ù†
def get_tehran_datetime():
    """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ ØªÙ‡Ø±Ø§Ù†"""
    tehran_now = datetime.now(TEHRAN_TZ)
    return tehran_now

def get_jalali_date():
    """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ"""
    tehran_now = get_tehran_datetime()
    jalali_date = jdatetime.datetime.fromgregorian(datetime=tehran_now)
    return jalali_date.strftime('%Y/%m/%d')

def get_tehran_time():
    """Ø¯Ø±ÛŒØ§ÙØª Ø²Ù…Ø§Ù† ØªÙ‡Ø±Ø§Ù†"""
    tehran_now = get_tehran_datetime()
    return tehran_now.strftime('%H:%M:%S')

# ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
async def analyze_results_with_ai(exam_data):
    """ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ† Ø¨Ø§ Hugging Face API"""
    try:
        if not HF_API_TOKEN:
            return "âŒ ØªÙˆÚ©Ù† API ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§Ù…Ú©Ø§Ù† ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
        
        course_name = exam_data.get('course_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
        topic_name = exam_data.get('topic_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
        total_questions = exam_data.get('total_questions', 0)
        correct_count = len(exam_data.get('correct_questions', []))
        wrong_count = len(exam_data.get('wrong_questions', []))
        unanswered_count = len(exam_data.get('unanswered_questions', []))
        score = exam_data.get('score', 0)
        elapsed_time = exam_data.get('elapsed_time', 0)
        question_pattern = exam_data.get('question_pattern', 'all')
        
        # Ø§ÛŒØ¬Ø§Ø¯ prompt Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        prompt = f"""
        Ø´Ù…Ø§ ÛŒÚ© Ù…Ø¹Ù„Ù… Ø¨Ø§ØªØ¬Ø±Ø¨Ù‡ Ù‡Ø³ØªÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ù†ØªØ§ÛŒØ¬ Ø§ÛŒÙ† Ø¢Ø²Ù…ÙˆÙ† Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:

        Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ø²Ù…ÙˆÙ†:
        - Ø¯Ø±Ø³: {course_name}
        - Ù…Ø¨Ø­Ø«: {topic_name}
        - Ø§Ù„Ú¯ÙˆÛŒ Ø³ÙˆØ§Ù„Ø§Øª: {get_pattern_name(question_pattern)}
        - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³ÙˆØ§Ù„Ø§Øª: {total_questions}
        - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ ØµØ­ÛŒØ­: {correct_count}
        - ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ø´ØªØ¨Ø§Ù‡: {wrong_count}
        - ØªØ¹Ø¯Ø§Ø¯ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®: {unanswered_count}
        - Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ: {score:.2f}%
        - Ø²Ù…Ø§Ù† ØµØ±Ù Ø´Ø¯Ù‡: {elapsed_time:.2f} Ø¯Ù‚ÛŒÙ‚Ù‡

        Ù„Ø·ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ùˆ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø²ÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:
        1. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù„ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
        2. Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ùˆ Ø¶Ø¹Ù
        3. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
        4. Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª
        5. Ù…Ø¯ÛŒØ±ÛŒØª Ø²Ù…Ø§Ù† (Ø§Ú¯Ø± Ø²Ù…Ø§Ù† Ù…Ø­Ø¯ÙˆØ¯ Ø¨ÙˆØ¯Ù‡)

        ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ¯ Ø±Ø§ Ù…Ø®ØªØµØ± Ùˆ Ù…ÙÛŒØ¯ (Ø­Ø¯Ø§Ú©Ø«Ø± 300 Ú©Ù„Ù…Ù‡) Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
        """
        
        api_url = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1"
        
        headers = {
            "Authorization": f"Bearer {HF_API_TOKEN}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 500,
                "temperature": 0.7,
                "do_sample": True,
                "return_full_text": False
            }
        }
        
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                analysis = result[0].get('generated_text', '').strip()
                # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†
                if prompt.strip() in analysis:
                    analysis = analysis.replace(prompt.strip(), "").strip()
                return analysis if analysis else "ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø®ÙˆØ¯ØªØ§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."
        else:
            return f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯: {response.status_code}"
            
    except Exception as e:
        logger.error(f"Error in AI analysis: {e}")
        return f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯: {str(e)}"
    
    return "ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ù†ØªØ§ÛŒØ¬ Ø±Ø§ Ø®ÙˆØ¯ØªØ§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."

# ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†ØªØ§ÛŒØ¬
def advanced_analysis(exam_data):
    """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ API"""
    course_name = exam_data.get('course_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
    topic_name = exam_data.get('topic_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
    total_questions = exam_data.get('total_questions', 0)
    correct_count = len(exam_data.get('correct_questions', []))
    wrong_count = len(exam_data.get('wrong_questions', []))
    unanswered_count = len(exam_data.get('unanswered_questions', []))
    score = exam_data.get('score', 0)
    elapsed_time = exam_data.get('elapsed_time', 0)
    question_pattern = exam_data.get('question_pattern', 'all')
    
    # Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¢Ù…Ø§Ø±ÛŒ
    accuracy_rate = (correct_count / total_questions) * 100 if total_questions > 0 else 0
    completion_rate = ((correct_count + wrong_count) / total_questions) * 100 if total_questions > 0 else 0
    time_per_question = elapsed_time / total_questions if total_questions > 0 else 0
    
    analysis = "ğŸ“Š **ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù†ØªØ§ÛŒØ¬:**\n\n"
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú©Ù„ÛŒ
    if score >= 80:
        analysis += "ğŸ‰ **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù„ÛŒ!** Ø´Ù…Ø§ ØªØ³Ù„Ø· Ø®ÙˆØ¨ÛŒ Ø±ÙˆÛŒ Ø§ÛŒÙ† Ù…Ø¨Ø­Ø« Ø¯Ø§Ø±ÛŒØ¯.\n"
    elif score >= 60:
        analysis += "ğŸ‘ **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„!** Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ…Ø±ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø±ÛŒØ¯.\n"
    elif score >= 40:
        analysis += "âš ï¸ **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯!** Ø¨Ø§ÛŒØ¯ Ø±ÙˆÛŒ Ø§ÛŒÙ† Ù…Ø¨Ø­Ø« Ø¨ÛŒØ´ØªØ± Ú©Ø§Ø± Ú©Ù†ÛŒØ¯.\n"
    else:
        analysis += "ğŸ”´ **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ!** Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø§ÛŒÙ† Ù…Ø¨Ø­Ø« Ø±Ø§ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯.\n"
    
    analysis += f"\nğŸ“ˆ **Ø¢Ù…Ø§Ø± Ø¯Ù‚ÛŒÙ‚:**\n"
    analysis += f"â€¢ Ø¯Ù‚Øª Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§: {accuracy_rate:.1f}%\n"
    analysis += f"â€¢ Ù…ÛŒØ²Ø§Ù† ØªÚ©Ù…ÛŒÙ„ Ø¢Ø²Ù…ÙˆÙ†: {completion_rate:.1f}%\n"
    analysis += f"â€¢ Ø²Ù…Ø§Ù† Ù…ØªÙˆØ³Ø· Ù‡Ø± Ø³ÙˆØ§Ù„: {time_per_question:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡\n"
    
    # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÛŒ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª
    if wrong_count > 0:
        wrong_percentage = (wrong_count / total_questions) * 100
        analysis += f"\nâŒ **ØªØ­Ù„ÛŒÙ„ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª:**\n"
        analysis += f"â€¢ {wrong_percentage:.1f}% Ø³ÙˆØ§Ù„Ø§Øª Ø§Ø´ØªØ¨Ø§Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡\n"
        
        if wrong_percentage > 30:
            analysis += "â€¢ **Ù‡Ø´Ø¯Ø§Ø±:** ØªØ¹Ø¯Ø§Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø¨Ø§Ù„Ø§ Ø§Ø³Øª! Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¯Ø± ÙÙ‡Ù… Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±ÛŒØ¯.\n"
        elif wrong_percentage > 15:
            analysis += "â€¢ **ØªÙˆØ¬Ù‡:** Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø§Ø±ÛŒØ¯.\n"
    
    # ØªØ­Ù„ÛŒÙ„ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®
    if unanswered_count > 0:
        unanswered_percentage = (unanswered_count / total_questions) * 100
        analysis += f"\nâ¸ï¸ **ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®â€ŒÙ‡Ø§:**\n"
        analysis += f"â€¢ {unanswered_percentage:.1f}% Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø® Ù…Ø§Ù†Ø¯Ù‡\n"
        
        if unanswered_percentage > 50:
            analysis += "â€¢ **Ù‡Ø´Ø¯Ø§Ø±:** Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª! Ø¨Ø§ÛŒØ¯ Ø³Ø±Ø¹Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯.\n"
        elif unanswered_percentage > 20:
            analysis += "â€¢ **ØªÙˆØ¬Ù‡:** Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Ø²Ù…Ø§Ù† Ø¯Ø§Ø±ÛŒØ¯.\n"
    
    # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
    analysis += f"\nğŸ’¡ **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯:**\n"
    
    if accuracy_rate < 70:
        analysis += "â€¢ Ù…ÙØ§Ù‡ÛŒÙ… Ø§ØµÙ„ÛŒ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯\n"
        analysis += "â€¢ Ø±ÙˆÛŒ Ø³ÙˆØ§Ù„Ø§Øª ØªØ´Ø±ÛŒØ­ÛŒ Ø¨ÛŒØ´ØªØ± ØªÙ…Ø±ÛŒÙ† Ú©Ù†ÛŒØ¯\n"
    
    if time_per_question > 2:
        analysis += "â€¢ ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ ØªØ³Øªâ€ŒØ²Ù†ÛŒ Ø³Ø±ÛŒØ¹ Ø±Ø§ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±ÛŒØ¯\n"
        analysis += "â€¢ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø§ Ø¯Ø± Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯\n"
    
    if wrong_count > correct_count / 2:
        analysis += "â€¢ Ù‚Ø¨Ù„ Ø§Ø² Ù¾Ø§Ø³Ø® Ø¯Ø§Ø¯Ù†ØŒ Ø³ÙˆØ§Ù„Ø§Øª Ø±Ø§ Ø¨Ø§ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯\n"
        analysis += "â€¢ Ø§Ø² Ø±ÙˆØ´ Ø­Ø°Ù Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØºÙ„Ø· Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯\n"
    
    analysis += "â€¢ Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒ ØªÙ…Ø±ÛŒÙ† Ú©Ù†ÛŒØ¯\n"
    analysis += "â€¢ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø®ÙˆØ¯ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø¨Ø±Ø·Ø±Ù Ú©Ù†ÛŒØ¯\n"
    
    return analysis

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
async def show_detailed_results(update: Update, context: ContextTypes.DEFAULT_TYPE, exam_data, exam_id=None):
    """Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    user_id = update.effective_user.id
    
    course_name = exam_data.get('course_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
    topic_name = exam_data.get('topic_name', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
    total_questions = exam_data.get('total_questions', 0)
    correct_count = len(exam_data.get('correct_questions', []))
    wrong_count = len(exam_data.get('wrong_questions', []))
    unanswered_count = len(exam_data.get('unanswered_questions', []))
    score = exam_data.get('score', 0)
    elapsed_time = exam_data.get('elapsed_time', 0)
    question_pattern = exam_data.get('question_pattern', 'all')
    jalali_date = exam_data.get('jalali_date', '')
    tehran_time = exam_data.get('tehran_time', '')
    
    # Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ù†ØªØ§ÛŒØ¬
    result_text = f"""
ğŸ“Š **Ù†ØªØ§ÛŒØ¬ Ø¢Ø²Ù…ÙˆÙ† Ø´Ù…Ø§:**

ğŸ“š Ø¯Ø±Ø³: {course_name}
ğŸ“– Ù…Ø¨Ø­Ø«: {topic_name}
ğŸ”¢ Ø§Ù„Ú¯Ùˆ: {get_pattern_name(question_pattern)}
ğŸ“… ØªØ§Ø±ÛŒØ®: {jalali_date}
â° Ø²Ù…Ø§Ù†: {tehran_time}

âœ… ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø® ØµØ­ÛŒØ­: {correct_count}
âŒ ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø³Ø® Ø§Ø´ØªØ¨Ø§Ù‡: {wrong_count}
â¸ï¸ ØªØ¹Ø¯Ø§Ø¯ Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®: {unanswered_count}
ğŸ“ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³ÙˆØ§Ù„Ø§Øª: {total_questions}
â° Ø²Ù…Ø§Ù† ØµØ±Ù Ø´Ø¯Ù‡: {elapsed_time:.2f} Ø¯Ù‚ÛŒÙ‚Ù‡

ğŸ“ˆ Ø¯Ø±ØµØ¯ Ø¨Ø¯ÙˆÙ† Ù†Ù…Ø±Ù‡ Ù…Ù†ÙÛŒ: {(correct_count/total_questions)*100:.2f}%
ğŸ“‰ Ø¯Ø±ØµØ¯ Ø¨Ø§ Ù†Ù…Ø±Ù‡ Ù…Ù†ÙÛŒ: {score:.2f}%

ğŸ”¢ Ø³ÙˆØ§Ù„Ø§Øª ØµØ­ÛŒØ­: {', '.join(map(str, exam_data.get('correct_questions', []))) if exam_data.get('correct_questions') else 'Ù†Ø¯Ø§Ø±Ø¯'}
ğŸ”¢ Ø³ÙˆØ§Ù„Ø§Øª ØºÙ„Ø·: {', '.join(map(str, exam_data.get('wrong_questions', []))) if exam_data.get('wrong_questions') else 'Ù†Ø¯Ø§Ø±Ø¯'}
ğŸ”¢ Ø³ÙˆØ§Ù„Ø§Øª Ø¨ÛŒâ€ŒÙ¾Ø§Ø³Ø®: {', '.join(map(str, exam_data.get('unanswered_questions', []))) if exam_data.get('unanswered_questions') else 'Ù†Ø¯Ø§Ø±Ø¯'}

ğŸ’¡ Ù†Ú©ØªÙ‡: Ù‡Ø± Û³ Ù¾Ø§Ø³Ø® Ø§Ø´ØªØ¨Ø§Ù‡ØŒ Ù…Ø¹Ø§Ø¯Ù„ Û± Ù¾Ø§Ø³Ø® ØµØ­ÛŒØ­ Ù†Ù…Ø±Ù‡ Ù…Ù†ÙÛŒ Ø¯Ø§Ø±Ø¯.
"""
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
    advanced_analysis_text = advanced_analysis(exam_data)
    result_text += f"\n{advanced_analysis_text}"
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ù„Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒØ´ØªØ±
    keyboard = [
        [InlineKeyboardButton("ğŸ¤– ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ AI", callback_data=f"ai_analysis_{exam_id}")],
        [InlineKeyboardButton("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ", callback_data=f"compare_results_{exam_id}")],
        [InlineKeyboardButton("ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬", callback_data=f"save_results_{exam_id}")],
        [InlineKeyboardButton("ğŸ”„ Ø¢Ø²Ù…ÙˆÙ† Ø¬Ø¯ÛŒØ¯", callback_data="new_exam")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    if update.callback_query:
        await update.callback_query.edit_message_text(result_text, reply_markup=reply_markup)
    else:
        await update.effective_message.reply_text(result_text, reply_markup=reply_markup)

# Ù…Ø¯ÛŒØ±ÛŒØª callback query Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
async def handle_analysis_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø¯ÛŒØ±ÛŒØª callback query Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    data = query.data
    
    if data.startswith("ai_analysis_"):
        exam_id = data.split("_")[2]
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        try:
            conn = get_db_connection()
            if conn:
                cur = conn.cursor()
                cur.execute(
                    "SELECT * FROM exams WHERE id = %s AND user_id = %s",
                    (exam_id, user_id)
                )
                exam_record = cur.fetchone()
                cur.close()
                conn.close()
                
                if exam_record:
                    # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ù‡ ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
                    exam_data = {
                        'course_name': exam_record[2],
                        'topic_name': exam_record[3],
                        'total_questions': exam_record[6],
                        'score': exam_record[11],
                        'elapsed_time': exam_record[8],
                        'question_pattern': exam_record[17],
                        'correct_questions': eval(exam_record[13]) if exam_record[13] else [],
                        'wrong_questions': eval(exam_record[12]) if exam_record[12] else [],
                        'unanswered_questions': eval(exam_record[14]) if exam_record[14] else []
                    }
                    
                    await query.edit_message_text("ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
                    
                    # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ
                    ai_analysis = await analyze_results_with_ai(exam_data)
                    
                    analysis_text = f"""
ğŸ¯ **ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†ØªØ§ÛŒØ¬:**

{ai_analysis}

ğŸ’¡ **Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:**
â€¢ Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø®ÙˆØ¯ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†ÛŒØ¯
â€¢ Ø±ÙˆÛŒ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù ØªÙ…Ø±Ú©Ø² Ú©Ù†ÛŒØ¯
â€¢ Ù…Ø¯ÛŒØ±ÛŒØª Ø²Ù…Ø§Ù† Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‡ÛŒØ¯
â€¢ Ø¢Ø²Ù…ÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ ØªÙ…Ø±ÛŒÙ† Ú©Ù†ÛŒØ¯
"""
                    
                    keyboard = [
                        [InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬", callback_data=f"back_to_results_{exam_id}")],
                        [InlineKeyboardButton("ğŸ”„ Ø¢Ø²Ù…ÙˆÙ† Ø¬Ø¯ÛŒØ¯", callback_data="new_exam")]
                    ]
                    reply_markup = InlineKeyboardMarkup(keyboard)
                    
                    await query.edit_message_text(analysis_text, reply_markup=reply_markup)
                    return
                    
        except Exception as e:
            logger.error(f"Error in AI analysis callback: {e}")
            await query.edit_message_text("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´Ù…Ù†Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
    
    elif data.startswith("compare_results_"):
        exam_id = data.split("_")[2]
        await show_comparison(update, context, user_id, exam_id)
    
    elif data.startswith("save_results_"):
        exam_id = data.split("_")[2]
        await query.answer("âœ… Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!", show_alert=True)
    
    elif data.startswith("back_to_results_"):
        exam_id = data.split("_")[3]
        # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ØµÙØ­Ù‡ Ù†ØªØ§ÛŒØ¬ (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø±Ø¯)
        await query.answer("Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù†ØªØ§ÛŒØ¬")
    
    elif data == "new_exam":
        await new_exam(update, context)

# Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ
async def show_comparison(update: Update, context: ContextTypes.DEFAULT_TYPE, user_id: int, current_exam_id: int):
    """Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ"""
    try:
        conn = get_db_connection()
        if not conn:
            await update.callback_query.answer("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡.")
            return
            
        cur = conn.cursor()
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ
        cur.execute(
            """
            SELECT id, course_name, topic_name, score, total_questions, jalali_date
            FROM exams 
            WHERE user_id = %s AND id != %s
            ORDER BY created_at DESC 
            LIMIT 5
            """,
            (user_id, current_exam_id)
        )
        
        previous_results = cur.fetchall()
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù†ØªÛŒØ¬Ù‡ ÙØ¹Ù„ÛŒ
        cur.execute(
            "SELECT course_name, topic_name, score, total_questions FROM exams WHERE id = %s",
            (current_exam_id,)
        )
        current_result = cur.fetchone()
        
        cur.close()
        conn.close()
        
        if not current_result:
            await update.callback_query.answer("âŒ Ù†ØªÛŒØ¬Ù‡ ÙØ¹Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return
        
        current_course, current_topic, current_score, current_total = current_result
        
        comparison_text = f"""
ğŸ“Š **Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ:**

ğŸ“š Ø¢Ø²Ù…ÙˆÙ† ÙØ¹Ù„ÛŒ:
â€¢ Ø¯Ø±Ø³: {current_course} - Ù…Ø¨Ø­Ø«: {current_topic}
â€¢ Ù†Ù…Ø±Ù‡: {current_score:.2f}% - ØªØ¹Ø¯Ø§Ø¯ Ø³ÙˆØ§Ù„Ø§Øª: {current_total}

"""
        
        if previous_results:
            comparison_text += "ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ù‚Ø¨Ù„ÛŒ:\n"
            for i, (exam_id, course, topic, score, total, date) in enumerate(previous_results, 1):
                trend = "ğŸ“ˆ" if score < current_score else "ğŸ“‰" if score > current_score else "â¡ï¸"
                comparison_text += f"{i}. {course} - {topic}\n"
                comparison_text += f"   Ù†Ù…Ø±Ù‡: {score:.2f}% {trend} - ØªØ§Ø±ÛŒØ®: {date}\n\n"
            
            # ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯
            avg_previous = sum(score for _, _, _, score, _, _ in previous_results) / len(previous_results)
            if current_score > avg_previous:
                comparison_text += "ğŸ‰ **ØªØ¨Ø±ÛŒÚ©! Ù¾ÛŒØ´Ø±ÙØª Ø¯Ø§Ø´ØªÙ‡â€ŒØ§ÛŒØ¯!**\n"
            elif current_score < avg_previous:
                comparison_text += "âš ï¸ **Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ…Ø±ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø±ÛŒØ¯!**\n"
            else:
                comparison_text += "â¡ï¸ **Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø´Ù…Ø§ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³Øª!**\n"
        else:
            comparison_text += "ğŸ“­ Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.\n"
        
        keyboard = [
            [InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data=f"back_to_results_{current_exam_id}")],
            [InlineKeyboardButton("ğŸ”„ Ø¢Ø²Ù…ÙˆÙ† Ø¬Ø¯ÛŒØ¯", callback_data="new_exam")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.callback_query.edit_message_text(comparison_text, reply_markup=reply_markup)
        
    except Exception as e:
        logger.error(f"Error in comparison: {e}")
        await update.callback_query.answer("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬.")

# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… Ø§Ù„Ú¯Ùˆ
def get_pattern_name(pattern):
    pattern_names = {
        'all': 'Ù‡Ù…Ù‡ Ø³ÙˆØ§Ù„Ø§Øª (Ù¾Ø´Øª Ø³Ø± Ù‡Ù…)',
        'alternate': 'ÛŒÚ©ÛŒ Ø¯Ø± Ù…ÛŒØ§Ù† (Ø²ÙˆØ¬/ÙØ±Ø¯)',
        'every_two': 'Ø¯Ùˆ ØªØ§ Ø¯Ø± Ù…ÛŒØ§Ù†',
        'every_three': 'Ø³Ù‡ ØªØ§ Ø¯Ø± Ù…ÛŒØ§Ù†'
    }
    return pattern_names.get(pattern, 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')

# Ø¯Ø± ØªØ§Ø¨Ø¹ handle_callback_query Ø§ØµÙ„ÛŒØŒ Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯:
async def handle_callback_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    # ... Ú©Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ...
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø¯ÛŒØ±ÛŒØª ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§
    if (query.data.startswith("ai_analysis_") or 
        query.data.startswith("compare_results_") or 
        query.data.startswith("save_results_") or
        query.data.startswith("back_to_results_")):
        await handle_analysis_callback(update, context)
        return
    
    # ... Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ...

# Ø¯Ø± ØªØ§Ø¨Ø¹ finish_correct_answersØŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù† Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø³Ø§Ø¯Ù‡ Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´Ø±ÙØªÙ‡:
# Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§ÛŒÙ†:
# await query.edit_message_text(result_text)

# Ø§Ø² Ø§ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:
exam_data = {
    'course_name': exam_setup.get('course_name'),
    'topic_name': exam_setup.get('topic_name'),
    'total_questions': total_questions,
    'score': final_percentage,
    'elapsed_time': elapsed_time,
    'question_pattern': exam_setup.get('question_pattern', 'all'),
    'jalali_date': jalali_date,
    'tehran_time': tehran_time,
    'correct_questions': correct_questions,
    'wrong_questions': wrong_questions,
    'unanswered_questions': unanswered_questions
}

# Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ø¯Ø±ÛŒØ§ÙØª ID
try:
    conn = get_db_connection()
    if conn:
        cur = conn.cursor()
        cur.execute(
            """
            INSERT INTO exams 
            (user_id, course_name, topic_name, start_question, end_question, total_questions, 
             exam_duration, elapsed_time, answers, correct_answers, score, wrong_questions, 
             unanswered_questions, jalali_date, tehran_time, question_pattern)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            RETURNING id
            """,
            (
                user_id,
                exam_setup.get('course_name'),
                exam_setup.get('topic_name'),
                exam_setup.get('start_question'),
                exam_setup.get('end_question'),
                total_questions,
                exam_setup.get('exam_duration'),
                elapsed_time,
                str(user_answers),
                correct_answers_str,
                final_percentage,
                str(wrong_questions),
                str(unanswered_questions),
                jalali_date,
                tehran_time,
                exam_setup.get('question_pattern', 'all')
            )
        )
        exam_id = cur.fetchone()[0]
        conn.commit()
        cur.close()
        conn.close()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        await show_detailed_results(update, context, exam_data, exam_id)
        
except Exception as e:
    logger.error(f"Error saving to database: {e}")
    # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø³Ø§Ø¯Ù‡ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
    await query.edit_message_text(result_text)

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
def main():
    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    if not init_db():
        logger.error("Failed to initialize database. Exiting.")
        return
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†
    application = Application.builder().token(TOKEN).build()
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("new_exam", new_exam))
    application.add_handler(CommandHandler("results", show_results))
    application.add_handler(CallbackQueryHandler(handle_callback_query))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª
    print("ğŸ¤– Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª...")
    application.run_polling()

if __name__ == "__main__":
    main()
